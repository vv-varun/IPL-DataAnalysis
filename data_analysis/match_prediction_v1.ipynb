{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "#\n",
    "import pandas as pd;\n",
    "\n",
    "# In this data set - we only have the current match stats of bowlers and matsman.\n",
    "data = pd.read_csv('../data_files/final_over_data.csv');\n",
    "\n",
    "# Use the match_id as the Key / Index column.\n",
    "data.set_index(\"match_id\", inplace = True)\n",
    "\n",
    "# We have runs to win (numerical data). If the runs to win in last over are more than 36, the match is anyways lost.\n",
    "# So, we'll convert it to Runs per bowl required. Anything above 36 will be considered as 7\n",
    "# We'll bin it so that we dont have the continious data.\n",
    "cut_labels = ['1','2','3','4','5','6', '7'];\n",
    "cut_bins = [0, 6, 12, 18, 24, 30, 36, 200];\n",
    "\n",
    "# Insert directly after runs to win column.\n",
    "data.insert(3,'RPB',pd.cut(data['runs_to_win'], bins=cut_bins, labels=cut_labels))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the simplest version of Analysis (my first version)\n",
    "# We'll use a Decision Tree Classifier\n",
    "#\n",
    "# \n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the training data into Train and Test.\n",
    "train_set, test_set = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Training columns. For now, I'm taking only few columns.\n",
    "feature_columns = [\"innings_1_score\",\"RPB\",\"wickets_in_hand\",\"bowler_econ\",\"bowler_boundaries\",\"batsman_sr\",\"boundaries\"]\n",
    "X = train_set[feature_columns]\n",
    "y = train_set[\"match_result\"]\n",
    "#y=y.astype('int')\n",
    "\n",
    "def decision_tree(params,feature,results):\n",
    "    classifier = tree.DecisionTreeClassifier(**params)\n",
    "    classifier = classifier.fit(feature,results)\n",
    "    return classifier\n",
    "\n",
    "def check_accuracy(classifier):\n",
    "    test_results = clf.predict(test_set[feature_columns])\n",
    "    return accuracy_score(test_set[\"match_result\"],test_results)\n",
    "\n",
    "def random_forest(params,feature,results):\n",
    "    classifier = RandomForestClassifier(**params)\n",
    "    classifier = classifier.fit(feature,results)\n",
    "    return classifier\n",
    "\n",
    "# For now, we'll create a default tree. We'll see the accuracy / complexity and then decide the parameters.\n",
    "# Some things to be adjusted are max_leaf_nodes\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with default parameters\n",
    "params = {}\n",
    "clf = decision_tree(params,X,y)\n",
    "print(\"Accuracy with default parameters is: \", check_accuracy(clf))\n",
    "\n",
    "params = {\"max_depth\": 5}\n",
    "clf = decision_tree(params,X,y)\n",
    "print(\"Accuracy with Max depth 5 is: \", check_accuracy(clf))\n",
    "\n",
    "params = {\"max_depth\": 10}\n",
    "clf = decision_tree(params,X,y)\n",
    "print(\"Accuracy with Max depth 10 is: \", check_accuracy(clf))\n",
    "\n",
    "params = {\"max_depth\": 15}\n",
    "clf = decision_tree(params,X,y)\n",
    "print(\"Accuracy with Max depth 15 is: \", check_accuracy(clf))\n",
    "\n",
    "params = {\"max_depth\": 20}\n",
    "clf = decision_tree(params,X,y)\n",
    "print(\"Accuracy with Max depth 20 is: \", check_accuracy(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with default parameters\n",
    "params = {}\n",
    "clf = random_forest(params,X,y)\n",
    "print(\"Accuracy with default parameters is: \", check_accuracy(clf))\n",
    "\n",
    "params = {\"max_depth\": 5}\n",
    "clf = random_forest(params,X,y)\n",
    "print(\"Accuracy with Max depth 5 is: \", check_accuracy(clf))\n",
    "\n",
    "params = {\"max_depth\": 10}\n",
    "clf = random_forest(params,X,y)\n",
    "print(\"Accuracy with Max depth 10 is: \", check_accuracy(clf))\n",
    "\n",
    "params = {\"max_depth\": 15}\n",
    "clf = random_forest(params,X,y)\n",
    "print(\"Accuracy with Max depth 15 is: \", check_accuracy(clf))\n",
    "\n",
    "params = {\"max_depth\": 20}\n",
    "clf = random_forest(params,X,y)\n",
    "print(\"Accuracy with Max depth 20 is: \", check_accuracy(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix to understand the prediction results.\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "X_test = test_set[feature_columns]\n",
    "y_test = test_set[\"match_result\"]\n",
    "plot_confusion_matrix(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the tree as a image.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cn=['Won','Lost']\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (8,8), dpi=1000)\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = feature_columns, \n",
    "               class_names=cn,\n",
    "               filled = True);\n",
    "fig.savefig('v1_tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model as a file\n",
    "from joblib import dump\n",
    "dump(clf, 'ml_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model from file\n",
    "from joblib import load\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mymodel = load('ml_model.joblib')\n",
    "\n",
    "tdf = pd.DataFrame([{'innings_1_score': 170,'RPB': 2,'wickets_in_hand': 5,'bowler_econ': 9,'bowler_boundaries': 7,'batsman_sr': 125,'boundaries': 3}])\n",
    "#tdf.head()\n",
    "pred_prob = mymodel.predict_proba(tdf)\n",
    "print(pred_prob)\n",
    "print(mymodel.classes_)\n",
    "print(mymodel.predict(tdf))\n",
    "print(pred_prob[0][1])\n",
    "#clf.decision_path([{'innings_1_score': 170,'RPB': 2,'wickets_in_hand': 5,'bowler_econ': 9,'bowler_boundaries': 7,'batsman_sr': 125,'boundaries': 3}])\n",
    "\n",
    "#accuracy_score(test_set[\"match_result\"],test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-alert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
